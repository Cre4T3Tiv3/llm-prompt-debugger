# Contributing to LLM Prompt Debugger

ðŸ‘‹ Thanks for considering a contribution! **LLM Prompt Debugger** is a developer-first UI for testing, tagging, and exporting LLM prompts â€” with built-in support for OpenAI, Claude, and Ollama. This guide will help you get started.

---

## Project Structure

```
llm-prompt-debugger/
â”œâ”€â”€ app/                        # Next.js app directory (App Router)
â”‚   â”œâ”€â”€ api/                   # API route handlers
â”‚   â”‚   â”œâ”€â”€ model-availability/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts       # Model availability validator
â”‚   â”‚   â””â”€â”€ llm/
â”‚   â”‚       â”œâ”€â”€ route.ts       # Legacy/main LLM route
â”‚   â”‚       â””â”€â”€ stream/
â”‚   â”‚           â””â”€â”€ route.ts   # Streaming response handler
â”‚   â”œâ”€â”€ globals.css            # Global TailwindCSS styles
â”‚   â”œâ”€â”€ layout.tsx             # Root layout component
â”‚   â””â”€â”€ page.tsx               # Main LLM debugger UI
â”‚
â”œâ”€â”€ components/                # Modular UI components
â”‚   â”œâ”€â”€ PromptHistory.tsx      # Tagging, export, delete prompt history
â”‚   â””â”€â”€ ui/                    # Reusable UI primitives
â”‚       â”œâ”€â”€ BulkExportBar.tsx
â”‚       â”œâ”€â”€ ExportPrompt.tsx
â”‚       â”œâ”€â”€ button.tsx
â”‚       â”œâ”€â”€ card.tsx
â”‚       â””â”€â”€ textarea.tsx
â”‚
â”œâ”€â”€ lib/                       # Core logic + utilities
â”‚   â”œâ”€â”€ availability.ts        # Shared model availability logic
â”‚   â”œâ”€â”€ formatPromptMarkdown.ts# Markdown formatter for exports
â”‚   â”œâ”€â”€ useLLM.ts              # Hook to stream LLM responses
â”‚   â””â”€â”€ utils.ts               # Generic helpers
â”‚
â”œâ”€â”€ docs/                      # Markdown documentation
â”‚   â”œâ”€â”€ E2E-GUIDE.md           # Local setup & usage walkthrough
â”‚   â””â”€â”€ KNOWN-WARNINGS.md      # Documented dependency warnings
â”‚
â”œâ”€â”€ scripts/                   # Internal utility scripts
â”‚   â””â”€â”€ generate-warnings-doc.ts
â”‚
â”œâ”€â”€ .github/                   # GitHub-specific configuration
â”‚   â”œâ”€â”€ ISSUE_TEMPLATE/
â”‚   â”‚   â””â”€â”€ bug_report.yml     # Template for bug reporting
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml             # CI lint/build/test workflow
â”‚       â””â”€â”€ warnings.yml       # Detects and logs dependency warnings
â”‚
â”œâ”€â”€ .editorconfig              # Editor formatting baseline
â”œâ”€â”€ .env                       # Local environment secrets (not committed)
â”œâ”€â”€ .env.example               # Reference .env values
â”œâ”€â”€ .gitignore                 # Ignored files and folders
â”œâ”€â”€ .prettierrc                # Prettier configuration
â”œâ”€â”€ eslint.config.mjs          # ESLint config module
â”œâ”€â”€ LICENSE                    # MIT License
â”œâ”€â”€ README.md                  # Overview, usage, badges
â”œâ”€â”€ CONTRIBUTOR.md             # You are here ðŸ› ï¸
â”œâ”€â”€ next-env.d.ts              # Auto-generated env typings
â”œâ”€â”€ package.json               # Project metadata + scripts
â”œâ”€â”€ pnpm-lock.yaml             # pnpm lockfile
â”œâ”€â”€ postcss.config.js          # PostCSS config for Tailwind
â”œâ”€â”€ tailwind.config.ts         # TailwindCSS config
â”œâ”€â”€ tsconfig.json              # TypeScript project config
â”œâ”€â”€ tsconfig.tsbuildinfo       # TypeScript build cache
â”œâ”€â”€ llm-prompt-debugger.zip    # Packaged release artifact (optional)
â”‚
â”œâ”€â”€ node_modules/              # Dependencies (auto-managed)
â””â”€â”€ .next/                     # Next.js build output (auto-generated)
```

---

## Getting Started

```bash
git clone https://github.com/Cre4T3Tiv3/llm-prompt-debugger.git
cd llm-prompt-debugger
pnpm install
pnpm dev
```

> â„¹ï¸ We officially support **pnpm** as the package manager of choice.
>
> This project uses a `pnpm-lock.yaml` lockfile to ensure consistent, reproducible dependency installs across environments.
>
> If you choose to use **npm** or **yarn** instead:
>
> - First, delete the existing `pnpm-lock.yaml` file.
> - Then run your package managerâ€™s install (`npm install` or `yarn install`) to regenerate a compatible lockfile (`package-lock.json` or `yarn.lock`).
> - âœ… Be sure to **update `.gitignore`** to ignore lockfiles from unused package managers (e.g., add `package-lock.json` if using `yarn`, or vice versa).
>
> For best compatibility and clean CI, we recommend sticking with **pnpm** unless you have a specific reason not to.

---

## Local Dev Tips

- This is a **Next.js 14** project using the `app/` directory structure.
- TailwindCSS is used for styling.
- Components are modular and designed for reusability.

### Inspect or preload prompt data

You can seed `localStorage` for testing:

```js
localStorage.setItem(
  "llm-debugger-history",
  JSON.stringify([
    /* your data */
  ])
);
```

---

## Code Standards

- TypeScript with `"strict": true` enforced via `tsconfig.json`
- TailwindCSS utility-first styling â€” no custom classes unless justified
- Modular, composable React components (`.tsx`)
- **Before committing or opening a PR**, run:

```bash
pnpm lint           # ESLint (with Prettier integration)
pnpm format         # Prettier formatting
pnpm tsc --noEmit   # TypeScript type check
```

---

## Commit Conventions

Follow [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/):

| Type        | Description                          |
| ----------- | ------------------------------------ |
| `feat:`     | New feature                          |
| `fix:`      | Bug fix                              |
| `docs:`     | Documentation only                   |
| `refactor:` | Code changes without behavior change |
| `style:`    | Formatting, missing semi-colons, etc |
| `chore:`    | Other changes (tooling, CI, etc)     |

---

## Supported LLMs

| Provider  | Model Name        | API Required        |
| --------- | ----------------- | ------------------- |
| OpenAI    | `gpt-4`, `gpt-4o` | âœ… `OPENAI_API_KEY` |
| Anthropic | `claude-3-opus`   | âœ… `CLAUDE_API_KEY` |
| Ollama    | `llama3`          | âŒ Local-only       |

---

## Feature Contributions

We welcome contributions for:

- ðŸ”Œ Model plugin support
- ðŸ§  Configurable UI for local LLMs
- ðŸ§ª Prompt input validation tooling
- ðŸ“¤ New export options (e.g., PDF, Notion)

Open a discussion if you're exploring a larger feature or integration.

---

## How to Contribute

1. Fork this repo
2. Create a new feature branch
3. Make your changes
4. Submit a pull request with clear, conventional commits

> ðŸ’¬ Feel free to ask for early feedback before diving deep!

---

## License

MIT Â© 2025 [@Cre4T3Tiv3](https://github.com/Cre4T3Tiv3)

---
